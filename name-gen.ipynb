{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vae.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FY8oV7oURTbK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "7c11d6cb-33bb-4b1a-d099-3adc750cb9d4"
      },
      "source": [
        "! wget https://raw.githubusercontent.com/ZardashtKaya/pytorch-name-generator/master/kurdish_names.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-11 13:20:35--  https://raw.githubusercontent.com/ZardashtKaya/pytorch-name-generator/master/kurdish_names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 43117 (42K) [text/plain]\n",
            "Saving to: ‘kurdish_names.txt’\n",
            "\n",
            "kurdish_names.txt   100%[===================>]  42.11K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-09-11 13:20:35 (1.67 MB/s) - ‘kurdish_names.txt’ saved [43117/43117]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9bOLEfTR0OS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "678afd18-9d48-4b8b-a1ab-acf8bba93f55"
      },
      "source": [
        "! pip install Unidecode"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: Unidecode\n",
            "Successfully installed Unidecode-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKeIR4o2EGYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import string\n",
        "import random\n",
        "import sys\n",
        "import unidecode\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZczMx9MQNrz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "all_chars = string.printable\n",
        "n_chars = len(all_chars)\n",
        "File = unidecode.unidecode(open('kurdish_names.txt').read())"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TykRioAxRe0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "    super(RNN,self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embed = nn.Embedding(input_size, hidden_size)\n",
        "    self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self,x ,hidden, cell):\n",
        "    out = self.embed(x)\n",
        "    out, (hidden,cell) = self.lstm(out.unsqueeze(1), (hidden,cell))\n",
        "    out = self.fc(out.reshape(out.shape[0],-1))\n",
        "    return out, (hidden,cell)\n",
        "  \n",
        "  def init_hidden(self, batch_size):\n",
        "    hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "    cell = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "    return hidden ,cell"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi7Wf7TiSjJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator():\n",
        "\n",
        "  def __init__(self):\n",
        "    self.chunk_len = 250\n",
        "    self.num_epochs = 5000\n",
        "    self.batch_size = 1\n",
        "    self.print_every = 50\n",
        "    self.hidden_size = 256\n",
        "    self.num_layers = 2\n",
        "    self.lr = 0.003\n",
        "  \n",
        "  def char_tensor(self, string):\n",
        "    tensor = torch.zeros(len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "      tensor[c] = all_chars.index(string[c])\n",
        "    return tensor\n",
        "  \n",
        "  def get_random_batch(self):\n",
        "    start_idx = random.randint(0, len(File) - self.chunk_len)\n",
        "    end_idx = start_idx + self.chunk_len + 1\n",
        "    text_str = File[start_idx:end_idx]\n",
        "    text_input = torch.zeros(self.batch_size, self.chunk_len)\n",
        "    text_target = torch.zeros(self.batch_size, self.chunk_len)\n",
        "\n",
        "    for i in range(self.batch_size):\n",
        "      text_input[i,:] = self.char_tensor(text_str[:-1])\n",
        "      text_target[i,:] = self.char_tensor(text_str[1:])\n",
        "\n",
        "    return  text_input.long(), text_target.long()\n",
        "  \n",
        "  def generate(self, initial_str = 'A', predict_len = 100, temperature=0.85):\n",
        "    hidden,cell = self.rnn.init_hidden(batch_size=self.batch_size)\n",
        "    initial_input = self.char_tensor(initial_str)\n",
        "    predicted = initial_str\n",
        "\n",
        "    for p in range(len(initial_str)-1):\n",
        "      _, (hidden,cell) = self.rnn(\n",
        "          initial_input[p].view(1).to(device), hidden,cell\n",
        "          )\n",
        "    last_char = initial_input[-1]\n",
        "\n",
        "    for p in range(predict_len):\n",
        "      output,(hidden,cell) = self.rnn(last_char.view(1).to(device), hidden,cell)\n",
        "      output_dist = output.data.view(-1).div(temperature).exp()\n",
        "      top_char = torch.multinomial(output_dist,1)[0]\n",
        "      predicted_char = all_chars[top_char]\n",
        "      predicted += predicted_char\n",
        "      last_char = self.char_tensor(predicted_char)\n",
        "    return predicted\n",
        "\n",
        "\n",
        "  \n",
        "  def train(self):\n",
        "    self.rnn = RNN(n_chars, self.hidden_size, self.num_layers, n_chars).to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(self.rnn.parameters(), lr=self.lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    writer = SummaryWriter(f'runs/names0')\n",
        "    print('=> Starting training')\n",
        "    for epoch in range(1, self.num_epochs + 1):\n",
        "      inp, target = self.get_random_batch()\n",
        "      hidden ,cell = self.rnn.init_hidden(batch_size=self.batch_size)\n",
        "\n",
        "      self.rnn.zero_grad()\n",
        "      loss = 0\n",
        "      inp = inp.to(device)\n",
        "      target = target.to(device)\n",
        "\n",
        "      for c in range(self.chunk_len):\n",
        "        output, (hidden,cell) = self.rnn(inp[:,c], hidden,cell)\n",
        "        loss += criterion(output, target[:,c])\n",
        "      \n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      loss = loss.item() / self.chunk_len\n",
        "\n",
        "      if epoch % self.print_every == 0:\n",
        "        print(f'Loss: {loss}')\n",
        "        print(self.generate())\n",
        "      writer.add_scalar('Training loss:', loss, global_step=epoch)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H86UXglkDgY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "814a6131-3da4-466d-8489-9db60a3af2e0"
      },
      "source": [
        "gennames = Generator()\n",
        "gennames.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> Starting training\n",
            "Loss: 2.39720654296875\n",
            "AA\n",
            "EON\n",
            "E\n",
            "AEO\n",
            "ERKC\n",
            "MA\n",
            "TIYAN\n",
            "MHMIRH\n",
            "HAYINA\n",
            "BERHA\n",
            "A\n",
            "DSYIRHARA\n",
            "LIRG\n",
            "LMON\n",
            "ZIGIDA\n",
            "SDSA\n",
            "ANIDT\n",
            "HHIAN\n",
            "DIYIREN\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcdBJ4O4mPnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}